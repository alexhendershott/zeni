# Spatial presence: next moves

Here is how to push spatial presence way further.

1. Two audio states  
Active listening stays tied to spacebar.  
Passive sensing runs all the time in the background.  
Passive sensing ignores speech content.  
It only grabs quick amplitude snapshots a few times per second.  
That gives you room location signals without fully recording.

2. Direction simulation even with one mic  
Even with a single mic you can fake directional awareness.  
You look for patterns.  
A soft sound means you shifted.  
A louder sound means you leaned in.  
A tiny scrape means arm movement.  
Train a simple rule set.  
Small bump sound to the left shifts Zeni’s face a bit to the left.  
Same for right.  
You can even cheat by reading the amplitude curve speed.  
Fast spike means something moved close.  
Slow curve means movement farther away.

3. Zeni reacts like a creature not a chatbot  
When passive sense fires  
Zeni does not talk.  
Zeni just shifts head  
tightens eyes  
moves shadow layer  
leans in or leans away.  
Feels like it knows where you are in the room.

4. Presence map  
Add three zones.  
Far.  
Mid.  
Near.  
Far means Zeni looks relaxed.  
Mid means Zeni becomes attentive.  
Near means Zeni gets bright and focused.  
You switch zones by looking at average ambient amplitude over two seconds.  
This makes it look like Zeni feels your proximity.

5. Motion memory  
If you move from left to right quickly  
Zeni tracks your arc.  
Just animate a head sweep.  
The brain reads that as social presence instantly.

Spacebar becomes one thing  
“go into full language mode”  
but everything else becomes continuous  
“Zeni is here  
Zeni is watching  
Zeni responds to the room.”
